<!--
Tuning application using AnalyzerNode and Web Audio API to stream and visualize
-->

<dom-module id='my-tuner'>
<template>
    <style type='text/css'>
    </style>
    <p>
    <input onclick='startAudioStream(this)' type='button' value='Use live audio'/>
    <input onclick='stopAudioStream(this)' type='button' disabled value='Stop'/>
    </p>
    <p><canvas id='tunerCanvas' width='550' height='400' onload='initCanvas()'></canvas></p>
    test
</template>

<script>
Polymer({
  is: 'my-tuner',
  ready: function() {  
    console.log(document.getElementsByTagName('tunerCanvas'));
  }
});

var myCanvas;
var canvasCtx;
var audio = document.querySelector('audio');
window.URL = window.URL || window.webkitURL;

// mozGetUserMedia deprecated but automatically switches
navigator.getUserMedia  = navigator.getUserMedia || navigator.webkitGetUserMedia ||
 navigator.mozGetUserMedia || navigator.msGetUserMedia;
var AudioContext = window.AudioContext || window.webkitAudioContext;
var audioCtx = new AudioContext();
var isStreaming = false;

var analyser = audioCtx.createAnalyser();
analyser.fftSize = 2048;
var bufferLength = analyser.frequencyBinCount;
var dataArray = new Uint8Array(bufferLength);
analyser.getByteTimeDomainData(dataArray);
analyser.getByteFrequencyData(dataArray);

function initCanvas() {
  myCanvas = document.getElementsByTagName('tunerCanvas');
  canvasCtx = myCanvas.getContext('2d');
}

function draw() {
  var drawVisual = requestAnimationFrame(draw);
  analyser.getByteTimeDomainData(dataArray);
  canvasCtx.fillStyle = 'rgb(0, 0, 0)';
  canvasCtx.fillRect(0, 0, myCanvas.width, myCanvas.height);
  canvasCtx.lineWidth = 2;
  canvasCtx.strokeStyle = 'rgb(0, 255, 255)';
  canvasCtx.beginPath();
  var sliceWidth = myCanvas.width * 1.0 / bufferLength;
  var x = 0;
  for (var i = 0; i < bufferLength; i++) {
    var v = dataArray[i] / 128.0;
    var y = v * myCanvas.height / 2;
    if (i === 0) {
      canvasCtx.moveTo(x, y);
    } else {
      canvasCtx.lineTo(x, y);
    }
    x += sliceWidth;
  }
  canvasCtx.lineTo(myCanvas.width, myCanvas.height / 2);
  canvasCtx.stroke();
}

// If user denies access to microphone
var onFail = function(e) {
  console.log('Access Denied!', e);
};
    
// If user allows access to microphone
var onSuccess = function(s) {
  isStreaming = true;
  console.log('onSuccess');
  var mediaStreamSource = audioCtx.createMediaStreamSource(s);
  mediaStreamSource.connect(analyser);
  // Comment/Uncomment to allow real-time playback for users
  mediaStreamSource.connect(audioCtx.destination);

  while (isStreaming) {
    draw();
  }
};

function startAudioStream(button) {
  if (navigator.getUserMedia) {
    button.disabled = true;
    button.nextElementSibling.disabled = false;
    navigator.getUserMedia({audio: true}, onSuccess, onFail);
  } else {
    console.log('navigator.getUserMedia not present');
  }
}

function stopAudioStream(button) {
  button.disabled = true;
  button.previousElementSibling.disabled = false;
  isStreaming = false;
  mediaStreamSource.stopAudioStream();
}

draw();
</script>
</dom-module>
